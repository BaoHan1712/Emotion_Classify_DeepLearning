import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F

# ======== 1Ô∏è‚É£ Load m√¥ h√¨nh v√† tokenizer ========
SAVE_DIR = "phobert_sentiment_model"  # Th∆∞ m·ª•c ch·ª©a model ƒë√£ l∆∞u
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print("üîÑ Loading model from:", SAVE_DIR)
tokenizer = AutoTokenizer.from_pretrained(SAVE_DIR)
model = AutoModelForSequenceClassification.from_pretrained(SAVE_DIR)
model.to(device)
model.eval()

# ======== 2Ô∏è‚É£ C√°c nh√£n ========
id2label = {0: "negative", 1: "neutral", 2: "positive"}

# ======== 3Ô∏è‚É£ H√†m d·ª± ƒëo√°n ========
def predict_sentiment(text):
    # Ti·ªÅn x·ª≠ l√Ω v√† m√£ h√≥a
    inputs = tokenizer(
        text,
        padding=True,
        truncation=True,
        max_length=128,
        return_tensors="pt"
    ).to(device)

    # D·ª± ƒëo√°n
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = F.softmax(logits, dim=-1)
        pred_id = torch.argmax(probs, dim=-1).item()

    label = id2label[pred_id]
    confidence = probs[0][pred_id].item()
    return label, confidence

# ======== 4Ô∏è‚É£ Ch·∫°y th·ª≠ ========
if __name__ == "__main__":
    print("‚úÖ PhoBERT Sentiment Model loaded successfully!")

    while True:
        text = input("\nNh·∫≠p c√¢u c·∫ßn ph√¢n t√≠ch c·∫£m x√∫c (ho·∫∑c g√µ 'exit' ƒë·ªÉ tho√°t): ")
        if text.lower() == "exit":
            break
        label, conf = predict_sentiment(text)
        print(f"üß† C·∫£m x√∫c d·ª± ƒëo√°n: {label.upper()} (ƒë·ªô tin c·∫≠y: {conf:.2%})")
